# üß† RAG-RPG: IA que responde perguntas sobre o meu mundo de fantasia

Este projeto usa **RAG (Retrieval-Augmented Generation)** para responder perguntas sobre o universo fict√≠cio Exandria RPG, utilizando arquivos `.txt` com a lore completa. Tudo roda **localmente**, sem depender de APIs externas.

---

## üåç Sobre o universo

Os textos carregados descrevem o mundo de Exandria RPG, suas cidades, reinos, conflitos hist√≥ricos, organiza√ß√µes m√°gicas e figuras lend√°rias como **Caroline Windspur**, a **Assembleia do C√©rbero**, os eventos do **Ano das Portas Abertas**, entre outros.

---

## ‚öôÔ∏è Como funciona

O projeto √© um pipeline local que usa:

- **[BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)** ‚Äì para gerar embeddings sem√¢nticos dos textos  
- **[Qdrant](https://qdrant.tech/)** ‚Äì banco vetorial para armazenar e buscar vetores  
- **[BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)** ‚Äì reranker para ordenar trechos por relev√¢ncia  
- **Modelos via [Ollama](https://ollama.com)** (ex.: `qwen2.5:7b`, `gemma3:4b-it-qat`, `llama3.1:8b-instruct`) ‚Äì LLM que gera a resposta final com base no contexto  
- **[Gradio](https://www.gradio.app/)** ‚Äì interface gr√°fica simples para intera√ß√£o no navegador  
- Tudo feito com **Python**, **Docker**, e acelera√ß√£o via **GPU**, se dispon√≠vel  

---

## üöÄ Como rodar o projeto

### 1. Pr√©-requisitos

- Python 3.12  
- [Docker + Docker Compose](https://docs.docker.com/get-docker/)  
- [Ollama](https://ollama.com) instalado  
- Git  

### 2. Clone o projeto

```bash
git clone https://github.com/ianandriani07/rag-rpg.git
cd rag-rpg
```

### 3. Crie um ambiente virtual

```bash
python -m venv .venv
# no Windows
.\.venv\Scripts\activate
# no Linux/Mac
source .venv/bin/activate
```

### 4. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 5. Suba o Qdrant com Docker

```bash
docker-compose up -d
```

### 6. Baixe o(s) modelo(s) do Ollama

```bash
ollama pull qwen2.5:7b
ollama pull gemma3:4b-it-qat
```

*(adicione outros modelos se quiser testar)*

### 7. Adicione seus arquivos de lore em `docs/`

Coloque seus arquivos `.txt` com a lore do seu mundo dentro da pasta `docs/`.

### 8. Rode a ingest√£o (indexa√ß√£o dos textos)

```bash
python ingest.py
```

### 9. Rode a interface (duas op√ß√µes)

#### üîπ Linha de comando (CLI)
```bash
python query.py
```

Digite perguntas como:

- Quem foi Gots e o que aconteceu com Toya?  
- O que foi o Ano das Portas Abertas?  
- Qual √© a origem da Assembleia do C√©rbero?  

Para sair, digite `sair`.

#### üîπ Interface gr√°fica (Gradio)
```bash
python query.py
```

Abra no navegador: [http://127.0.0.1:7860](http://127.0.0.1:7860)

---

## ‚ú® Exemplo de uso (CLI)

```bash
Digite sua pergunta sobre o mundo: O que foi o Ano das Portas Abertas?

üß† Resposta da IA:
O Ano das Portas Abertas √© um evento celebrado como um exemplo da bondade e uni√£o entre os humanoides,
que se originou durante os conflitos...
```

---

## üß© Arquitetura (resumo t√©cnico)

```
[docs/*.txt] ‚Üí [embedding com bge-m3] ‚Üí [armazenamento no Qdrant]
                       ‚Üì
               [busca sem√¢ntica top-k=20]
                       ‚Üì
             [reranking com bge-reranker]
                       ‚Üì
         [top 5 trechos] ‚Üí [prompt para modelo Ollama]
                       ‚Üì
                 üß† Resposta gerada!
```
